{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"test_3.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"mginZGe4lt3C"},"source":["# Data preparation"]},{"cell_type":"code","metadata":{"id":"nbWLUxZwZV6l","executionInfo":{"status":"ok","timestamp":1612133121619,"user_tz":-60,"elapsed":2285,"user":{"displayName":"Denis Muçollari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggwo8SFk_-iOieHLdWvSSIN9ehXsrs7FfHBNi_Q=s64","userId":"03181733068213323635"}}},"source":["import os\n","import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","import random\n","\n","SEED = 1234\n","tf.random.set_seed(SEED)\n","random.seed(SEED)\n","\n","test_name = 'test_2'"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"656CZGn7VtVE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1612133121622,"user_tz":-60,"elapsed":2271,"user":{"displayName":"Denis Muçollari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggwo8SFk_-iOieHLdWvSSIN9ehXsrs7FfHBNi_Q=s64","userId":"03181733068213323635"}},"outputId":"c9c6f9ea-440f-4268-dc71-ce599ad7cc79"},"source":["# Set the base directory for Colab and non Colab environment\n","if 'google.colab' in str(get_ipython()):\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","  base_dir = '/content/drive/My Drive/AN2DL/homework_3'\n","else:\n","  base_dir = os.getcwd()\n","\n","# Unzip the data set\n","dataset_dir = 'VQA_Dataset'\n","if not os.path.exists(dataset_dir):\n","    !unzip '/content/drive/MyDrive/AN2DL/homework_3/anndl-2020-vqa.zip'"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JGMuBoZ39Hn-","executionInfo":{"status":"ok","timestamp":1612133121624,"user_tz":-60,"elapsed":2262,"user":{"displayName":"Denis Muçollari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggwo8SFk_-iOieHLdWvSSIN9ehXsrs7FfHBNi_Q=s64","userId":"03181733068213323635"}}},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Create training ImageDataGenerator object for images\n","train_img_data_gen = ImageDataGenerator(rotation_range=10,\n","                                        width_shift_range=10,\n","                                        height_shift_range=10,\n","                                        zoom_range=0.3,\n","                                        horizontal_flip=True,\n","                                        vertical_flip=True,\n","                                        fill_mode='nearest',\n","                                        rescale=1./255)\n","\n","# Create validation ImageDataGenerator object\n","valid_img_data_gen = ImageDataGenerator(rescale=1./255)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"a7mWSFGRZdNG","executionInfo":{"status":"ok","timestamp":1612133121625,"user_tz":-60,"elapsed":2257,"user":{"displayName":"Denis Muçollari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggwo8SFk_-iOieHLdWvSSIN9ehXsrs7FfHBNi_Q=s64","userId":"03181733068213323635"}}},"source":["import json\n","from PIL import Image\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","# Define a custom dataset class extending Keras Sequence\n","class CustomDataset(tf.keras.utils.Sequence):\n","  \"\"\"\n","    CustomDataset inheriting from tf.keras.utils.Sequence.\n","\n","    3 main methods:\n","      - __init__: save dataset params\n","      - __len__: return the total number of samples in the dataset\n","      - __getitem__: return a sample from the dataset\n","  \"\"\"\n","\n","\n","  LABELS_DICT = {\n","    '0': 0,\n","    '1': 1,\n","    '2': 2,\n","    '3': 3,\n","    '4': 4,\n","    '5': 5,\n","    'apple': 6,\n","    'baseball': 7,\n","    'bench': 8,\n","    'bike': 9,\n","    'bird': 10,\n","    'black': 11,\n","    'blanket': 12,\n","    'blue': 13,\n","    'bone': 14,\n","    'book': 15,\n","    'boy': 16,\n","    'brown': 17,\n","    'cat': 18,\n","    'chair': 19,\n","    'couch': 20,\n","    'dog': 21,\n","    'floor': 22,\n","    'food': 23,\n","    'football': 24,\n","    'girl': 25,\n","    'grass': 26,\n","    'gray': 27,\n","    'green': 28,\n","    'left': 29,\n","    'log': 30,\n","    'man': 31,\n","    'monkey bars': 32,\n","    'no': 33,\n","    'nothing': 34,\n","    'orange': 35,\n","    'pie': 36,\n","    'plant': 37,\n","    'playing': 38,\n","    'red': 39,\n","    'right': 40,\n","    'rug': 41,\n","    'sandbox': 42,\n","    'sitting': 43,\n","    'sleeping': 44,\n","    'soccer': 45,\n","    'squirrel': 46,\n","    'standing': 47,\n","    'stool': 48,\n","    'sunny': 49,\n","    'table': 50,\n","    'tree': 51,\n","    'watermelon': 52,\n","    'white': 53,\n","    'wine': 54,\n","    'woman': 55,\n","    'yellow': 56,\n","    'yes': 57\n","  }\n","\n","\n","  def __init__(self, which_subset, dataset_items, tokenizer=None, max_question_length=None, img_generator=None, out_shape=None):\n","    \"\"\"\n","      Initialize the object.\n","\n","      Keyword arguments:\n","      which_subset -- 'training' for the training set, else 'validation'\n","      tokenizer -- tokenizer object for the 'validatio' set, in case of 'training' the object will be created\n","      max_question_length -- max length of a question of the training set (used for tokenizing 'validation'), in case of 'training' the parameter will be calculated\n","      img_generator -- ImageDataGenerator objet to apply to the images or None\n","      out_shape -- output shape for the images, a tuple (height, width) or None for original size\n","    \"\"\"\n","\n","    # Splitting training and validation\n","    training_count = int(0.8 * len(dataset_items))\n","    validation_count = len(dataset_items) - training_count\n","\n","    training_items = dataset_items[:training_count]\n","    validation_items = dataset_items[-validation_count:]\n","\n","    if which_subset == 'training':\n","      # Creating Tokenizer\n","      tokenizer = Tokenizer()\n","      train_questions = list(map(lambda x: x['question'], training_items))\n","\n","      # Fit tokenizer and tokenize training questions\n","      tokenizer.fit_on_texts(train_questions)\n","      tokenized_train_questions = tokenizer.texts_to_sequences(train_questions)\n","\n","      max_question_length = max(len(question) for question in tokenized_train_questions)\n","\n","      question_inputs = pad_sequences(tokenized_train_questions, maxlen=max_question_length, padding='post')\n","      items = training_items\n","\n","    else:\n","      # Using tokenizer from parameters to tokenize validation questions\n","      valid_questions = list(map(lambda x: x['question'], validation_items))\n","      tokenized_valid_questions = tokenizer.texts_to_sequences(valid_questions)\n","      question_inputs = pad_sequences(tokenized_valid_questions, maxlen=max_question_length, padding='post')\n","      items = validation_items\n","    \n","    # Setting dimension of the dictionary\n","    dictionary_dim = len(tokenizer.word_index)\n","    \n","    # Set class properties\n","    self.dataset_file = dataset_file\n","    self.which_subset = which_subset\n","    self.items = items\n","    self.question_inputs = question_inputs\n","    self.max_question_length = max_question_length\n","    self.dictionary_dim = dictionary_dim\n","    self.tokenizer = tokenizer\n","    self.img_generator = img_generator\n","    self.out_shape = out_shape\n","\n","  def __len__(self):\n","    \"\"\"\n","      Return the length of the dataset.\n","    \"\"\"\n","    return len(self.items)\n","\n","  def __getitem__(self, index):\n","    \"\"\"\n","      Return an item from the set.\n","\n","      Keyword arguments:\n","      index -- index of the item to return\n","    \"\"\"\n","\n","    # Read Image\n","    curr_item = self.items[index]\n","    img_id = curr_item['image_id']\n","    img = Image.open(os.path.join(dataset_dir, 'Images', img_id + '.png'))\n","\n","    # Convert image from RGBA to RGB\n","    img = img.convert('RGB')\n","\n","    # Resize image\n","    if self.out_shape is not None:\n","      img = img.resize(self.out_shape)\n","\n","    img_arr = np.array(img)\n","\n","    if self.img_generator is not None:\n","      # Perform data augmentation\n","      # Get a random transformation from the ImageDataGenerator and we can apply it to the image\n","      img_t = self.img_generator.get_random_transform(img_arr.shape, seed=SEED)\n","      img_arr = self.img_generator.apply_transform(img_arr, img_t)\n","\n","    # Convert answer to one-hot\n","    answer = np.zeros(len(self.LABELS_DICT))\n","    answer[self.LABELS_DICT[curr_item['answer']]] = 1\n","\n","    return (self.question_inputs[index], img_arr/255), answer"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"QolQ3xviAaGy","executionInfo":{"status":"ok","timestamp":1612133123111,"user_tz":-60,"elapsed":3736,"user":{"displayName":"Denis Muçollari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggwo8SFk_-iOieHLdWvSSIN9ehXsrs7FfHBNi_Q=s64","userId":"03181733068213323635"}}},"source":["# Set the sizes for the reshaped images\n","red = 0.8\n","img_w = int(700*red)\n","img_h = int(400*red)\n","\n","num_classes = 58\n","\n","# Set batch size\n","bs = 16\n","\n","dataset_filepath = os.path.join(dataset_dir, 'train_questions_annotations.json')\n","with open(dataset_filepath, 'r') as f:\n","  dataset_file = json.load(f)\n","\n","items = list(map(lambda x: x[1], dataset_file.items()))\n","random.shuffle(items)\n","\n","# Create training and validation set generators\n","dataset = CustomDataset('training', dataset_items=items, img_generator=train_img_data_gen, out_shape=(img_w, img_h))\n","dataset_valid = CustomDataset('validation', dataset_items=items, tokenizer=dataset.tokenizer, max_question_length=dataset.max_question_length, img_generator=valid_img_data_gen, out_shape=(img_w, img_h))"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rk14AY2SBVdf","executionInfo":{"status":"ok","timestamp":1612133123830,"user_tz":-60,"elapsed":4449,"user":{"displayName":"Denis Muçollari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggwo8SFk_-iOieHLdWvSSIN9ehXsrs7FfHBNi_Q=s64","userId":"03181733068213323635"}}},"source":["# Create training data set from the generator\n","train_dataset = tf.data.Dataset.from_generator(lambda: dataset,\n","                                               output_types=((np.int32, np.float32), np.int32),\n","                                               output_shapes=(([dataset.max_question_length,], [img_h, img_w, 3]), (58)))\n","train_dataset = train_dataset.batch(bs)\n","\n","train_dataset = train_dataset.repeat()\n","\n","# Create validation data set from the generator\n","valid_dataset = tf.data.Dataset.from_generator(lambda: dataset_valid,\n","                                               output_types=((np.int32, np.float32), np.int32),\n","                                               output_shapes=(([dataset.max_question_length,], [img_h, img_w, 3]), (58)))\n","valid_dataset = valid_dataset.batch(1)\n","\n","valid_dataset = valid_dataset.repeat()"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fs8X5Op17wyX"},"source":["# Model"]},{"cell_type":"code","metadata":{"id":"xTTw8rirmctn","executionInfo":{"status":"ok","timestamp":1612133147115,"user_tz":-60,"elapsed":27728,"user":{"displayName":"Denis Muçollari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggwo8SFk_-iOieHLdWvSSIN9ehXsrs7FfHBNi_Q=s64","userId":"03181733068213323635"}}},"source":["# Load GloVe embedding dictionary\n","embeddings_index = {}\n","f = open(os.path.join(base_dir, 'glove.6B', 'glove.6B.300d.txt'))\n","for line in f:\n","    values = line.split()\n","    word = values[0]\n","    coefs = np.asarray(values[1:], dtype='float32')\n","    embeddings_index[word] = coefs\n","f.close()"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"RDj_987wmehd","executionInfo":{"status":"ok","timestamp":1612133147120,"user_tz":-60,"elapsed":27727,"user":{"displayName":"Denis Muçollari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggwo8SFk_-iOieHLdWvSSIN9ehXsrs7FfHBNi_Q=s64","userId":"03181733068213323635"}}},"source":["# Create embedding matrix from data set tokenizer and GloVe\n","embedding_matrix = np.zeros((dataset.dictionary_dim + 1, 300))\n","for word, i in dataset.tokenizer.word_index.items():\n","    embedding_vector = embeddings_index.get(word)\n","    if embedding_vector is not None:\n","        # words not found in embedding index will be all-zeros.\n","        embedding_matrix[i] = embedding_vector"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"vmI5p4sHbm3S","executionInfo":{"status":"ok","timestamp":1612133147120,"user_tz":-60,"elapsed":27721,"user":{"displayName":"Denis Muçollari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggwo8SFk_-iOieHLdWvSSIN9ehXsrs7FfHBNi_Q=s64","userId":"03181733068213323635"}}},"source":["class TransformerEncoder(tf.keras.layers.Layer):\n","    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n","        super(TransformerEncoder, self).__init__()\n","        self.att = tf.keras.layers.MultiHeadAttention(num_heads, embed_dim)\n","        self.ffn = tf.keras.Sequential(\n","            [tf.keras.layers.Dense(ff_dim, activation=\"relu\"),\n","             tf.keras.layers.Dropout(rate),\n","             tf.keras.layers.Dense(embed_dim)]\n","        )\n","        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.dropout1 = tf.keras.layers.Dropout(rate)\n","\n","    def call(self, inputs, training=True):\n","        if len(inputs) == 3:\n","            attn_output = self.att(inputs[0], inputs[1], inputs[2])\n","        if len(inputs) == 2:\n","            attn_output = self.att(inputs[0], inputs[1], inputs[1])\n","        if len(inputs) == 1:\n","            attn_output = self.att(inputs[0], inputs[0], inputs[0])\n","\n","        attn_output = self.dropout1(attn_output, training=training)\n","        out1 = self.layernorm1(inputs[0] + attn_output)\n","        \n","        ffn_output = self.ffn(out1)\n","        return self.layernorm2(out1 + ffn_output)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"km7TGPINTxYA","executionInfo":{"status":"ok","timestamp":1612133147121,"user_tz":-60,"elapsed":27717,"user":{"displayName":"Denis Muçollari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggwo8SFk_-iOieHLdWvSSIN9ehXsrs7FfHBNi_Q=s64","userId":"03181733068213323635"}}},"source":["class TokenAndPositionEmbedding(tf.keras.layers.Layer):\r\n","    def __init__(self, maxlen, vocab_size, embed_dim, embedding_matrix):\r\n","        super(TokenAndPositionEmbedding, self).__init__()\r\n","        self.token_emb = tf.keras.layers.Embedding(input_dim=vocab_size,\r\n","                                                   output_dim=embed_dim,\r\n","                                                   weights=[embedding_matrix],\r\n","                                                   trainable=False)\r\n","        self.pos_emb = tf.keras.layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\r\n","\r\n","    def call(self, x):\r\n","        maxlen = tf.shape(x)[-1]\r\n","        positions = tf.range(start=0, limit=maxlen, delta=1)\r\n","        positions = self.pos_emb(positions)\r\n","        x = self.token_emb(x)\r\n","        return x + positions"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"5yMAKoodjSSf","executionInfo":{"status":"ok","timestamp":1612133147122,"user_tz":-60,"elapsed":27711,"user":{"displayName":"Denis Muçollari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggwo8SFk_-iOieHLdWvSSIN9ehXsrs7FfHBNi_Q=s64","userId":"03181733068213323635"}}},"source":["class SelfAttention(tf.keras.layers.Layer):\r\n","    def __init__(self, ff_dim, rate=0.2):\r\n","        super(SelfAttention, self).__init__()\r\n","        self.att = tf.keras.layers.Attention()\r\n","        self.ffn = tf.keras.Sequential(\r\n","            [tf.keras.layers.Dense(ff_dim, activation=\"relu\"),\r\n","             tf.keras.layers.Dropout(rate)]\r\n","        )\r\n","        self.layernorm = tf.keras.layers.LayerNormalization()\r\n","\r\n","    def call(self, inputs, training=True):\r\n","        attn = self.att([inputs, inputs])\r\n","        ffn_output = self.ffn(attn)      \r\n","        return self.layernorm(inputs + ffn_output)"],"execution_count":11,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Free up RAM in case the model definition cells were run multiple times\n","tf.keras.backend.clear_session()\n","\n","input_length = dataset.max_question_length\n","vocab_size = dataset.dictionary_dim + 1\n","embed_dim = 300  # Embedding size for each token\n","num_heads = 8  # Number of attention heads\n","encode_dim = 300\n","ff_dim = 600  # Hidden layer size in feed forward network inside transformer\n","\n","# CNN for extracing image features\n","image_input = tf.keras.layers.Input(shape=(img_h, img_w, 3))\n","image_enc = tf.keras.applications.ResNet101(input_tensor=image_input, include_top=False, weights='imagenet').output\n","\n","image_enc = tf.keras.layers.GlobalAveragePooling2D()(image_enc)\n","image_enc = tf.keras.layers.Dropout(0.2)(image_enc)\n","image_enc = tf.keras.layers.Reshape((8,256))(image_enc)\n","\n","image_enc = SelfAttention(256)(image_enc)\n","image_enc = tf.keras.layers.Dense(128, activation=\"relu\")(image_enc)\n","image_enc = SelfAttention(128)(image_enc)\n","image_enc = tf.keras.layers.Dense(300, activation=\"relu\")(image_enc)\n","image_enc = SelfAttention(300)(image_enc)\n","\n","# Question embedding\n","question_input = tf.keras.layers.Input(shape=(input_length), dtype='int32')\n","question_embedding = TokenAndPositionEmbedding(maxlen=input_length,\n","                                               vocab_size=vocab_size,\n","                                               embed_dim=embed_dim,\n","                                               embedding_matrix=embedding_matrix)(question_input)\n","                                                                            \n","question_enc = TransformerEncoder(encode_dim, num_heads, ff_dim)([question_embedding])\n","question_enc = TransformerEncoder(encode_dim, num_heads, ff_dim)([question_enc])\n","question_enc = TransformerEncoder(encode_dim, num_heads, ff_dim)([question_enc])\n","question_enc = TransformerEncoder(encode_dim, num_heads, ff_dim)([question_enc])\n","\n","attention_vector_1 = tf.keras.layers.Attention()([question_enc, image_enc])\n","attention_vector_2 = tf.keras.layers.Attention()([image_enc, question_enc])\n","\n","attention_vector_1 = tf.keras.layers.GlobalAveragePooling1D()(attention_vector_1)\n","attention_vector_2 = tf.keras.layers.GlobalAveragePooling1D()(attention_vector_2)\n","\n","merged = tf.keras.layers.Concatenate()([attention_vector_1, attention_vector_2])\n","merged = tf.keras.layers.Dropout(0.5)(merged)\n","output = tf.keras.layers.Dense(units=num_classes, activation='softmax')(merged)\n","model = tf.keras.models.Model(inputs=[question_input, image_input], outputs=output)\n","\n","# Visualize created model\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"iiXyQ7dgovJe"},"source":["# Training"]},{"cell_type":"code","metadata":{"id":"KnnXNjSal_en","executionInfo":{"status":"ok","timestamp":1612133170142,"user_tz":-60,"elapsed":660,"user":{"displayName":"Denis Muçollari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggwo8SFk_-iOieHLdWvSSIN9ehXsrs7FfHBNi_Q=s64","userId":"03181733068213323635"}}},"source":["# Loss function\n","loss = tf.keras.losses.CategoricalCrossentropy() \n","\n","# Learning rate and oprimizer\n","lr = 1e-4\n","optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n","\n","# Number of epochs\n","epochs = 100\n","\n","# Validation metrics\n","metrics = ['accuracy']\n","\n","# Compile Model\n","model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"ck6esfPtmNYP","executionInfo":{"status":"ok","timestamp":1612133178346,"user_tz":-60,"elapsed":1064,"user":{"displayName":"Denis Muçollari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggwo8SFk_-iOieHLdWvSSIN9ehXsrs7FfHBNi_Q=s64","userId":"03181733068213323635"}}},"source":["exp_dir = os.path.join(base_dir, test_name)\n","if not os.path.exists(exp_dir):\n","  os.makedirs(exp_dir)\n","    \n","callbacks = []\n","\n","# Checkpoint callback, generate a checkpoint at each epoch\n","# There is only one checkpoint overwritten only if the new one has an lower validation loss\n","ckpt_dir = os.path.join(exp_dir, 'checkpoints')\n","if not os.path.exists(ckpt_dir):\n","  os.makedirs(ckpt_dir)\n","checkpoint = os.path.join(ckpt_dir, 'checkpoint_' + test_name + '.ckpt')\n","ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint,\n","                                                   save_weights_only=True,\n","                                                   monitor='val_loss',\n","                                                   mode='min',\n","                                                   save_best_only=True)\n","callbacks.append(ckpt_callback)\n","\n","# Callback for tensorboard logs\n","tb_dir = os.path.join(exp_dir, 'tb_logs')\n","if not os.path.exists(tb_dir):\n","  os.makedirs(tb_dir)\n","    \n","tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n","                                             profile_batch=0,\n","                                             histogram_freq=1)\n","callbacks.append(tb_callback)\n","\n","# Callback for early stopping in order to optimize the number of epochs\n","es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=5)\n","callbacks.append(es_callback)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"SPkEUjArmH4a","executionInfo":{"status":"aborted","timestamp":1612133147123,"user_tz":-60,"elapsed":27689,"user":{"displayName":"Denis Muçollari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggwo8SFk_-iOieHLdWvSSIN9ehXsrs7FfHBNi_Q=s64","userId":"03181733068213323635"}}},"source":["%load_ext tensorboard\n","%tensorboard --logdir '$base_dir'"],"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# If there exists a checkpoint it's loaded, otherwise the model is trained\n","# If train is True and there exists a checkpoint the trainig continues from it\n","\n","train = True\n","load = False\n","\n","if os.path.exists(os.path.join(ckpt_dir, 'checkpoint')) and load:\n","  model.load_weights(checkpoint)\n","\n","if train:\n","  model.fit(x=train_dataset,\n","            epochs=epochs,\n","            steps_per_epoch=len(dataset)/bs,\n","            validation_data=valid_dataset,\n","            validation_steps=len(dataset_valid),\n","            callbacks=callbacks)\n","  \n","  # Reload the weights to load the best checkpoint\n","  model.load_weights(checkpoint)\n","\n","  # Save model as h5\n","  # model_file = os.path.join(exp_dir, test_name + '.h5')\n","  # model.save(model_file, include_optimizer=False)"]},{"cell_type":"markdown","metadata":{"id":"yKtCtnG2qL_S"},"source":["# Prediction"]},{"cell_type":"code","metadata":{"id":"jBv3ewrx4U19"},"source":["import json\r\n","\r\n","# Image data set path\r\n","test_filepath = os.path.join(dataset_dir, 'test_questions.json')\r\n","\r\n","# Load test dictionary\r\n","with open(test_filepath, 'r') as f:\r\n","  test_items = json.load(f)\r\n","\r\n","# Initialize submission dict\r\n","submission_dict = {}\r\n","\r\n","for key, item in test_items.items():\r\n","  # Open test image\r\n","  img = Image.open(os.path.join(dataset_dir, 'Images', item['image_id'] + '.png'))\r\n","\r\n","  # Convert image to RGB and resize\r\n","  img = img.convert('RGB')\r\n","  img = img.resize((img_w, img_h))\r\n","  img_arr = np.array(img)/255\r\n","\r\n","  # Tokenize question\r\n","  question = item['question']\r\n","  tokenized_question = dataset.tokenizer.texts_to_sequences([question])\r\n","  question_input = pad_sequences(tokenized_question, maxlen=dataset.max_question_length, padding='post')\r\n","\r\n","  # Prediction\r\n","  out_sigmoid = model.predict([question_input, np.expand_dims(img_arr, axis=0)])[0]\r\n","\r\n","  prediction = tf.argmax(out_sigmoid, -1).numpy()\r\n","\r\n","  submission_dict[key] = prediction"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C3ESdlE_hHzd"},"source":["import os\n","\n","csv_fname = 'submission.csv'\n","\n","# Write submission dict as csv file\n","with open(os.path.join(exp_dir, csv_fname), 'w') as f:\n","\n","    f.write('Id,Category\\n')\n","\n","    for key, value in submission_dict.items():\n","        f.write(key + ',' + str(value) + '\\n')"],"execution_count":null,"outputs":[]}]}