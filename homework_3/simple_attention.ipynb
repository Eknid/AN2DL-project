{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"test_attention_2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"mginZGe4lt3C"},"source":["# Data preparation"]},{"cell_type":"code","metadata":{"id":"nbWLUxZwZV6l"},"source":["import os\n","import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","import random\n","\n","SEED = 1234\n","tf.random.set_seed(SEED)\n","random.seed(SEED)\n","\n","test_name = 'test_attention'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"656CZGn7VtVE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1610131017168,"user_tz":-60,"elapsed":114070,"user":{"displayName":"Denis Muçollari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggwo8SFk_-iOieHLdWvSSIN9ehXsrs7FfHBNi_Q=s64","userId":"03181733068213323635"}},"outputId":"af0b7bf5-00d0-459f-f518-316ec1414a32"},"source":["# Set the base directory for Colab and non Colab environment\n","if 'google.colab' in str(get_ipython()):\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","  base_dir = '/content/drive/My Drive/AN2DL/homework_3'\n","else:\n","  base_dir = os.getcwd()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lSG0Dbc7Mg7p"},"source":["dataset_dir = 'VQA_Dataset'\n","if not os.path.exists(dataset_dir):\n","    !unzip '/content/drive/MyDrive/AN2DL/homework_3/anndl-2020-vqa.zip'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JGMuBoZ39Hn-"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Create training ImageDataGenerator object for images\n","train_img_data_gen = ImageDataGenerator(rotation_range=10,\n","                                        width_shift_range=10,\n","                                        height_shift_range=10,\n","                                        zoom_range=0.3,\n","                                        horizontal_flip=True,\n","                                        vertical_flip=True,\n","                                        fill_mode='nearest',\n","                                        rescale=1./255)\n","\n","# Create validation ImageDataGenerator object\n","valid_img_data_gen = ImageDataGenerator(rescale=1./255)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lSTQgaa5aRdp"},"source":["# Load the dictionary containing the references to files\n","dataset_filepath = os.path.join(dataset_dir, 'train_questions_annotations.json')\n","with open(dataset_filepath, 'r') as f:\n","  dataset_file = json.load(f)\n","\n","# Splitting training and validation\n","training_count = int(0.8 * len(dataset_file))\n","validation_count = len(dataset_file) - training_count\n","\n","items = list(map(lambda x: x[1], dataset_file.items()))\n","random.shuffle(items)\n","\n","training_items = items[:training_count]\n","validation_items = items[-validation_count:]\n","\n","# Creating Tokenizer\n","tokenizer = Tokenizer()\n","\n","# Fit tokenizer on training questions\n","train_questions = list(map(lambda x: x['question'], training_items))\n","tokenizer.fit_on_texts(train_questions)\n","\n","# Using tokenizer to tokenize training questions\n","tokenized_train_questions = tokenizer.texts_to_sequences(train_questions)\n","max_question_length = max(len(question) for question in tokenized_train_questions)\n","question_inputs_train = pad_sequences(tokenized_train_questions, maxlen=max_question_length, padding='post')\n","\n","# Using tokenizer to tokenize validation questions\n","valid_questions = list(map(lambda x: x['question'], validation_items))\n","tokenized_valid_questions = tokenizer.texts_to_sequences(valid_questions)\n","question_inputs_valid = pad_sequences(tokenized_valid_questions, maxlen=max_question_length, padding='post')\n","\n","# Setting dimension of the dictionary\n","dictionary_dim = len(tokenizer.word_index)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a7mWSFGRZdNG"},"source":["import json\n","from PIL import Image\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","# Define a custom dataset class extending Keras Sequence\n","class CustomDataset(tf.keras.utils.Sequence):\n","  \"\"\"\n","    CustomDataset inheriting from tf.keras.utils.Sequence.\n","\n","    3 main methods:\n","      - __init__: save dataset params\n","      - __len__: return the total number of samples in the dataset\n","      - __getitem__: return a sample from the dataset\n","  \"\"\"\n","\n","\n","  LABELS_DICT = {\n","    '0': 0,\n","    '1': 1,\n","    '2': 2,\n","    '3': 3,\n","    '4': 4,\n","    '5': 5,\n","    'apple': 6,\n","    'baseball': 7,\n","    'bench': 8,\n","    'bike': 9,\n","    'bird': 10,\n","    'black': 11,\n","    'blanket': 12,\n","    'blue': 13,\n","    'bone': 14,\n","    'book': 15,\n","    'boy': 16,\n","    'brown': 17,\n","    'cat': 18,\n","    'chair': 19,\n","    'couch': 20,\n","    'dog': 21,\n","    'floor': 22,\n","    'food': 23,\n","    'football': 24,\n","    'girl': 25,\n","    'grass': 26,\n","    'gray': 27,\n","    'green': 28,\n","    'left': 29,\n","    'log': 30,\n","    'man': 31,\n","    'monkey bars': 32,\n","    'no': 33,\n","    'nothing': 34,\n","    'orange': 35,\n","    'pie': 36,\n","    'plant': 37,\n","    'playing': 38,\n","    'red': 39,\n","    'right': 40,\n","    'rug': 41,\n","    'sandbox': 42,\n","    'sitting': 43,\n","    'sleeping': 44,\n","    'soccer': 45,\n","    'squirrel': 46,\n","    'standing': 47,\n","    'stool': 48,\n","    'sunny': 49,\n","    'table': 50,\n","    'tree': 51,\n","    'watermelon': 52,\n","    'white': 53,\n","    'wine': 54,\n","    'woman': 55,\n","    'yellow': 56,\n","    'yes': 57\n","  }\n","\n","\n","  def __init__(self, items, question_inputs=None, max_question_length=None, img_generator=None, out_shape=None):\n","    \"\"\"\n","      Initialize the object.\n","\n","      Keyword arguments:\n","      which_subset -- 'training' for the training set, else 'validation'\n","      tokenizer -- tokenizer object for the 'validatio' set, in case of 'training' the object will be created\n","      max_question_length -- max length of a question of the training set (used for tokenizing 'validation'), in case of 'training' the parameter will be calculated\n","      img_generator -- ImageDataGenerator objet to apply to the images or None\n","      out_shape -- output shape for the images, a tuple (height, width) or None for original size\n","    \"\"\"\n","    \n","    # Set class properties\n","    self.items = items\n","    self.question_inputs = question_inputs\n","    self.max_question_length = max_question_length\n","    self.img_generator = img_generator\n","    self.out_shape = out_shape\n","\n","  def __len__(self):\n","    \"\"\"\n","      Return the length of the dataset.\n","    \"\"\"\n","    return len(self.items)\n","\n","  def __getitem__(self, index):\n","    \"\"\"\n","      Return an item from the set.\n","\n","      Keyword arguments:\n","      index -- index of the item to return\n","    \"\"\"\n","\n","    # Read Image\n","    curr_item = self.items[index]\n","    img_id = curr_item['image_id']\n","    img = Image.open(os.path.join(dataset_dir, 'Images', img_id + '.png'))\n","\n","    # Convert image from RGBA to RGB\n","    img = img.convert('RGB')\n","\n","    # Resize image\n","    if self.out_shape is not None:\n","      img = img.resize(self.out_shape)\n","\n","    img_arr = np.array(img)\n","\n","    if self.img_generator is not None:\n","      # Perform data augmentation\n","      # Get a random transformation from the ImageDataGenerator and we can apply it to the image\n","      img_t = self.img_generator.get_random_transform(img_arr.shape, seed=SEED)\n","      img_arr = self.img_generator.apply_transform(img_arr, img_t)\n","\n","    # Convert answer to one-hot\n","    answer = np.zeros(len(self.LABELS_DICT))\n","    answer[self.LABELS_DICT[curr_item['answer']]] = 1\n","\n","    return (self.question_inputs[index], np.float32(img_arr)), answer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QolQ3xviAaGy"},"source":["# Set the sizes for the reshaped images\n","img_w = 350\n","img_h = 200\n","\n","# Set the number of classes\n","num_classes = 58\n","\n","# Set batch size\n","bs = 64\n","\n","# Create training and validation set generators\n","dataset = CustomDataset(training_items, question_inputs_train, max_question_length, img_generator=train_img_data_gen, out_shape=(img_w, img_h))\n","dataset_valid = CustomDataset(validation_items, question_inputs_valid, max_question_length, img_generator=valid_img_data_gen, out_shape=(img_w, img_h))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rk14AY2SBVdf"},"source":["# Create training data set from the generator\n","train_dataset = tf.data.Dataset.from_generator(lambda: dataset,\n","                                               output_types=((np.int32, np.float32), np.int32),\n","                                               output_shapes=(([dataset.max_question_length,], [img_h, img_w, 3]), (num_classes)))\n","train_dataset = train_dataset.batch(bs)\n","\n","train_dataset = train_dataset.repeat()\n","\n","# Create validation data set from the generator\n","valid_dataset = tf.data.Dataset.from_generator(lambda: dataset_valid,\n","                                               output_types=((np.int32, np.float32), np.int32),\n","                                               output_shapes=(([dataset.max_question_length,], [img_h, img_w, 3]), (num_classes)))\n","valid_dataset = valid_dataset.batch(1)\n","\n","valid_dataset = valid_dataset.repeat()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fs8X5Op17wyX"},"source":["# Model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xTTw8rirmctn","executionInfo":{"status":"ok","timestamp":1610131227211,"user_tz":-60,"elapsed":324077,"user":{"displayName":"Denis Muçollari","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggwo8SFk_-iOieHLdWvSSIN9ehXsrs7FfHBNi_Q=s64","userId":"03181733068213323635"}},"outputId":"c8d9377c-e2b3-4bfc-e712-ec441daee600"},"source":["embeddings_index = {}\n","f = open(os.path.join(base_dir, 'glove.6B', 'glove.6B.50d.txt'))\n","for line in f:\n","    values = line.split()\n","    word = values[0]\n","    coefs = np.asarray(values[1:], dtype='float32')\n","    embeddings_index[word] = coefs\n","f.close()\n","\n","print('Found %s word vectors.' % len(embeddings_index))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 400000 word vectors.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RDj_987wmehd"},"source":["embedding_matrix = np.zeros((dataset.dictionary_dim + 1, 50))\n","for word, i in dataset.tokenizer.word_index.items():\n","    embedding_vector = embeddings_index.get(word)\n","    if embedding_vector is not None:\n","        # words not found in embedding index will be all-zeros.\n","        embedding_matrix[i] = embedding_vector"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UR3pZB_fxD2H"},"source":["def conv2D(x, filters, k_size=3, strirdes=1, relu=0, pool_size=0):\n","    x = tf.keras.layers.Conv2D(filters=filters, \n","                               kernel_size=k_size,\n","                               strides=strirdes,\n","                               padding='same',\n","                               kernel_regularizer='l2',\n","                               input_shape=[None])(x)\n","    if relu:\n","        x = tf.keras.layers.ReLU()(x)\n","    if pool_size:\n","        x = tf.keras.layers.MaxPool2D(pool_size=pool_size)(x)\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6CVJpF5JsD9Q"},"source":["def vision_embending(inputs, out_length, question_length):\n","    x = tf.keras.applications.DenseNet121(input_tensor=inputs, include_top=False, weights='imagenet').output\n","    out_put = []\n","\n","    for i in range(question_length):\n","        y = conv2D(x, out_length, k_size=1, strirdes=1, relu=1)\n","        y = tf.keras.layers.GlobalAveragePooling2D()(y)\n","        out_put.append(y)\n","    \n","    x = tf.keras.layers.Concatenate()(out_put)\n","\n","    return tf.keras.layers.Reshape((question_length, out_length))(x)"],"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Free up RAM in case the model definition cells were run multiple times\n","tf.keras.backend.clear_session()\n","\n","input_length = dataset.max_question_length\n","input_dim = dataset.dictionary_dim + 1\n","output_dim = 50\n","\n","image_input = tf.keras.layers.Input(shape=(img_h, img_w, 3))\n","encoded_image = vision_embending(image_input, 512, input_length)\n","\n","\n","# Define RNN for language input\n","question_input = tf.keras.layers.Input(shape=(input_length), dtype='int32')\n","embedded_question = tf.keras.layers.Embedding(input_dim=input_dim,\n","                                              output_dim=output_dim,\n","                                              input_length=input_length,\n","                                              weights=[embedding_matrix],\n","                                              trainable=False)(question_input)\n","encoded_question, question_output, _ = tf.keras.layers.LSTM(512, return_sequences=True, return_state=True)(embedded_question)\n","\n","attention_vector = tf.keras.layers.Attention()([encoded_question, encoded_image])\n","\n","attention_output = tf.keras.layers.GlobalAveragePooling1D()(attention_vector)\n","\n","\n","# Combine CNN and RNN and create final model\n","merged = tf.keras.layers.multiply([question_output, attention_output])\n","merged = tf.keras.layers.Dropout(0.3)(merged)\n","output = tf.keras.layers.Dense(units=num_classes, activation='softmax')(merged)\n","model = tf.keras.models.Model(inputs=[question_input, image_input], outputs=output)\n","\n","# Visualize created model\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"iiXyQ7dgovJe"},"source":["# Training"]},{"cell_type":"code","metadata":{"id":"KnnXNjSal_en"},"source":["# Loss function\n","loss = tf.keras.losses.CategoricalCrossentropy() \n","\n","# Learning rate and oprimizer\n","lr = 1e-3\n","optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n","\n","# Number of epochs\n","epochs = 100\n","\n","# Validation metrics\n","metrics = ['accuracy']\n","\n","# Compile Model\n","model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ck6esfPtmNYP"},"source":["exp_dir = os.path.join(base_dir, test_name)\n","if not os.path.exists(exp_dir):\n","  os.makedirs(exp_dir)\n","    \n","callbacks = []\n","\n","# Checkpoint callback, generate a checkpoint at each epoch\n","# There is only one checkpoint overwritten only if the new one has an lower validation loss\n","ckpt_dir = os.path.join(exp_dir, 'checkpoints')\n","if not os.path.exists(ckpt_dir):\n","  os.makedirs(ckpt_dir)\n","checkpoint = os.path.join(ckpt_dir, 'checkpoint_' + test_name + '.ckpt')\n","ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint,\n","                                                   save_weights_only=True,\n","                                                   monitor='val_loss',\n","                                                   mode='min',\n","                                                   save_best_only=True)\n","callbacks.append(ckpt_callback)\n","\n","# Callback for tensorboard logs\n","tb_dir = os.path.join(exp_dir, 'tb_logs')\n","if not os.path.exists(tb_dir):\n","  os.makedirs(tb_dir)\n","    \n","tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n","                                             profile_batch=0,\n","                                             histogram_freq=1)\n","callbacks.append(tb_callback)\n","\n","# Callback for early stopping in order to optimize the number of epochs\n","es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=5)\n","callbacks.append(es_callback)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SPkEUjArmH4a"},"source":["#%load_ext tensorboard\n","#%tensorboard --logdir '$base_dir'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"04N_zH9Xmzdn"},"source":["# If there exists a checkpoint it's loaded, otherwise the model is trained\n","# If train is True and there exists a checkpoint the trainig continues from it\n","\n","train = True\n","load = True\n","\n","if os.path.exists(os.path.join(ckpt_dir, 'checkpoint')) and load:\n","  model.load_weights(checkpoint)\n","else:\n","  train = True\n","\n","if train: \n","  model.fit(x=train_dataset,\n","            epochs=epochs,\n","            initial_epoch=24,\n","            steps_per_epoch=len(dataset)/bs,\n","            validation_data=valid_dataset,\n","            validation_steps=len(dataset_valid),\n","            callbacks=callbacks)\n","  \n","  # Reload the weights to load the best checkpoint\n","  model.load_weights(checkpoint)\n","\n","  # Save model as h5\n","  #model_file = os.path.join(exp_dir, test_name + '.h5')\n","  #model.save(model_file, include_optimizer=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7snT91Gn39id"},"source":["# Nuova sezione"]},{"cell_type":"markdown","metadata":{"id":"yKtCtnG2qL_S"},"source":["# Prediction"]},{"cell_type":"code","metadata":{"id":"jmWoKPvq38Tl"},"source":["# Reload the weights to load the best checkpoint\n","model.load_weights(checkpoint)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-TGi3cxn4i6r"},"source":["import json\n","\n","# Image data set generator and path\n","test_img_data_gen = ImageDataGenerator(rescale=1./255)\n","test_filepath = os.path.join(dataset_dir, 'test_questions.json')\n","\n","# Load test dictionary\n","with open(test_filepath, 'r') as f:\n","  test_items = json.load(f)\n","\n","# Initialize submission dict\n","submission_dict = {}\n","\n","for key, item in test_items.items():\n","  # Open test image\n","  img = Image.open(os.path.join(dataset_dir, 'Images', item['image_id'] + '.png'))\n","\n","  # Convert image to RGB and resize\n","  img = img.convert('RGB')\n","  img = img.resize((img_w, img_h))\n","  img_arr = np.array(img)\n","\n","  # Apply test transformation\n","  img_t = test_img_data_gen.get_random_transform(img_arr.shape, seed=SEED)\n","  img_arr = np.float32(test_img_data_gen.apply_transform(img_arr, img_t))\n","\n","  # Tokenize question\n","  question = item['question']\n","  tokenized_question = dataset.tokenizer.texts_to_sequences([question])\n","  question_input = pad_sequences(tokenized_question, maxlen=dataset.max_question_length, padding='post')\n","\n","  # Prediction\n","  out_sigmoid = model.predict([question_input, np.expand_dims(img_arr, axis=0)])[0]\n","\n","  prediction = tf.argmax(out_sigmoid, -1)\n","  \n","  submission_dict[key] = prediction.numpy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C3ESdlE_hHzd"},"source":["import os\n","\n","csv_fname = 'submission.csv'\n","\n","# Write submission dict\n","with open(os.path.join(exp_dir, csv_fname), 'w') as f:\n","\n","    f.write('Id,Category\\n')\n","\n","    for key, value in submission_dict.items():\n","        f.write(key + ',' + str(value) + '\\n')"],"execution_count":null,"outputs":[]}]}